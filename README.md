# TSF Paper
Reading list for research topics in Time Series Forecasting (TSF).


## Transformer.
Date|Method|Conference|Paper Title and Paper Interpretation (In Chinese)|Code
-----|----|-----|-----|-----
19-06-29|[LogTrans](https://arxiv.org/abs/1907.00235)|NIPS 2019|Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting|[flowforecast](https://github.com/AIStream-Peelout/flow-forecast/blob/master/flood_forecast/transformer_xl/transformer_bottleneck.py)
20-06-05|[AST](https://proceedings.neurips.cc/paper/2020/file/c6b8c8d762da15fa8dbbdfb6baf9e260-Paper.pdf)|NIPS 2020|Adversarial Sparse Transformer for Time Series Forecasting|[AST](https://github.com/hihihihiwsf/AST)
20-12-14|[Informer](https://arxiv.org/abs/2012.07436)|AAAI 2021|[Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting](https://zhuanlan.zhihu.com/p/467523291)|[Informer](https://github.com/zhouhaoyi/Informer2020)
21-06-24|[Autoformer](https://arxiv.org/abs/2106.13008)|NIPS 2021|Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting|[Autoformer](https://github.com/thuml/Autoformer)
21-10-05|[Pyraformer](https://openreview.net/pdf?id=0EXmFzUn5I)|ICLR 2022|Pyraformer: Low-complexity Pyramidal Attention for Long-range Time Series Modeling and Forecasting|[Pyraformer](https://github.com/alipay/Pyraformer)
22-01-30|[FEDformer](https://arxiv.org/abs/2201.12740)|ICML 2022|FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting|[FEDformer](https://github.com/MAZiqing/FEDformer)
22-02-23|[Preformer](https://arxiv.org/abs/2202.11356)|Arxiv 2022|Preformer: Predictive Transformer with Multi-Scale Segment-wise Correlations for Long-Term Time Series Forecasting|None
22-05-16|[MANF](https://arxiv.org/abs/2205.07493)|Arxiv 2022|Multi-scale Attention Flow for Probabilistic Time Series Forecasting|None
22-05-18|[FiLM](https://arxiv.org/abs/2205.08897)|Arxiv 2022|FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting|None
22-05-24|[FreDo](https://arxiv.org/abs/2205.12301)|Arxiv 2022|FreDo: Frequency Domain-based Long-Term Time Series Forecasting|None
22-05-26|[DLinear](https://arxiv.org/abs/2205.13504)|Arxiv 2022|Are Transformers Effective for Time Series Forecasting?|[DLinear](https://github.com/cure-lab/DLinear)
22-05-28|[Non-stationary Transformer](https://arxiv.org/abs/2205.14415)|Arxiv 2022|Non-stationary Transformers: Rethinking the Stationarity in Time Series Forecasting|None
22-06-08|[Scaleformer](https://arxiv.org/abs/2206.04038)|Arxiv 2022|[Scaleformer: Iterative Multi-scale Refining Transformers for Time Series Forecasting](https://zhuanlan.zhihu.com/p/535556231)|None
22-06-24|[TreeDRNet](https://arxiv.org/abs/2206.12106)|Arxiv 2022|TreeDRNet: A Robust Deep Model for Long Term Time Series Forecasting|None

## RNN.
Date|Method|Conference|Paper Title and Paper Interpretation (In Chinese)|Code
-----|----|-----|-----|-----
## TCN.
Date|Method|Conference|Paper Title and Paper Interpretation (In Chinese)|Code
-----|----|-----|-----|-----
## GNN.

| Date | Method | Conference | Paper Title and Paper Interpretation (In Chinese) | Code |
| ---- | ------ | ---------- | ------------------------------------------------- | ---- |
|      |        |            |                                                   |      |

## Normalizing Flow.

Date|Method|Conference|Paper Title and Paper Interpretation (In Chinese)|Code
-----|----|-----|-----|-----
## Theory.
Date|Method|Conference| Paper Title and Paper Interpretation (In Chinese) |Code
-----|----|-----|-----|-----

## Other.
Date|Method|Conference|Paper Title and Paper Interpretation (In Chinese)|Code
-----|----|-----|-----|-----
